INFO-FLOW: Workspace /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1 opened at Tue Mar 11 17:52:20 CET 2025
Execute       send_msg_by_id INFO @200-1505@%s%s default  vivado 
INFO: [HLS 200-1505] Using default flow_target 'vivado'
Execute     config_array_partition -maximum_size 4096 
INFO: [HLS 200-1510] Running: config_array_partition -maximum_size 4096 
INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.
ERROR: [HLS 200-642] The 'config_array_partition -maximum_size' command is not supported.
Command     config_array_partition done; error code: 1; 
Execute     config_compile -name_max_length 80 
INFO: [HLS 200-1510] Running: config_compile -name_max_length 80 
INFO: [XFORM 203-1161] The maximum of name length is set to 80.
Execute     set_part xcvu13p-flga2577-2-e 
INFO: [HLS 200-1510] Running: set_part xcvu13p-flga2577-2-e 
Execute       create_platform xcvu13p-flga2577-2-e -board  
DBG:HLSDevice: Trying to load device library: /opt/Xilinx/Vitis_HLS/2023.2/lib/lnx64.o/libxv_hlsvwrap.so
DBG:HLSDevice: first parts/arch.xml in RDI_DATADIR: /opt/Xilinx/Vivado/2023.2/data/parts/arch.xml
DBG:HLSDevice: init success
INFO: [HLS 200-1611] Setting target device to 'xcvu13p-flga2577-2-e'
Command       create_platform done; 1.49 sec.
Execute       source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/common/xilinx.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/plb46.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/axi4.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/nativeAXI4.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/saxilite.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/scripts/xilinxcoregen.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/XilEDKCoreGen.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/dds_compiler.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/util.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/xfft.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/xfir.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/DSP48/dsp48.gen 
Execute       ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute       config_compile -quiet -complex-mul-dsp=0 
INFO: [XFORM 203-1161] The maximum of name length is set to 80.
Command     set_part done; 1.6 sec.
Execute     config_schedule -enable_dsp_full_reg=false 
INFO: [HLS 200-1510] Running: config_schedule -enable_dsp_full_reg=false 
Execute     create_clock -period 5 -name default 
INFO: [HLS 200-1510] Running: create_clock -period 5 -name default 
Execute       ap_set_clock -name default -period 5 -default=false 
INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.
Execute     set_clock_uncertainty 12.5% default 
INFO: [HLS 200-1510] Running: set_clock_uncertainty 12.5% default 
Execute       ap_set_clock -name default -uncertainty 0.625 -unit % 
INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.
Execute     csim_design 
INFO: [HLS 200-1510] Running: csim_design 
INFO-FLOW: Running SLX 'csim' proc: ::SLX::run_csim
INFO: [SIM 211-2] *************** CSIM start ***************
INFO: [SIM 211-4] CSIM will launch GCC as the compiler.
Execute       send_msg_by_id INFO @200-2036@%s debug 
INFO: [HLS 200-2036] Building debug C Simulation binaries
Execute       ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute       source run_sim.tcl 
INFO: [SIM 211-1] CSim done with 0 errors.
INFO: [SIM 211-3] *************** CSIM finish ***************
Command     csim_design done; 12 sec.
INFO: [HLS 200-111] Finished Command csim_design CPU user time: 10.55 seconds. CPU system time: 0.89 seconds. Elapsed time: 12 seconds; current allocated memory: 0.219 MB.
Execute     csynth_design 
INFO: [HLS 200-1510] Running: csynth_design 
INFO-FLOW: Running SLX 'csynth' proc: ::SLX::run_csynth
Execute       elaborate -effort=medium -skip_syncheck=0 -keep_printf=0 -skip_cdt=0 -skip_transform=0 -ng=0 -g=0 -opt_fp=0 -from_csynth_design=1 
INFO: [HLS 200-111] Finished File checks and directory preparation: CPU user time: 0.08 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.1 seconds; current allocated memory: 254.348 MB.
Execute         set_directive_top myproject -name=myproject 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/tps/tcl/tcllib1.11.1/yaml/huddle.tcl 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/tps/tcl/tcllib1.11.1/yaml/json2huddle.tcl 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/tps/tcl/tcllib1.11.1/try/try.tcl 
INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... 
INFO-FLOW: Compiling one TU...
INFO-FLOW: Handling firmware/myproject.cpp as C++
Execute         ap_part_info -name xcvu13p-flga2577-2-e -data info 
INFO-FLOW: Running: GCC PP 39
INFO-FLOW: Source preprocessing
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang firmware/myproject.cpp -foptimization-record-file=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.cpp.clang.diag.yml -mllvm -pass-remarks-missed=reflow|pasta|unroll -mllvm -pass-remarks=reflow|pasta|unroll|inline -fno-limit-debug-info -gcc-toolchain /opt/Xilinx/Vitis_HLS/2023.2/tps/lnx64/gcc-8.3.0 -fhls -fno-exceptions -insert-hls-directive=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/all.directive.json -E -std=c++0x -fno-math-errno -c -emit-llvm -mllvm -disable-llvm-optzns -Werror=implicit-function-declaration -Werror=implicit-hls-streams -Werror=return-type -Wpragmas -Wunused-parameter -Wdump-hls-pragmas -Wno-error=dump-hls-pragmas -hls-clock-period=5 -fno-threadsafe-statics -fno-use-cxa-atexit -target fpga64-xilinx-linux-gnu -fno-threadsafe-statics -fno-use-cxa-atexit -D__VITIS_HLS__ -DAESL_SYN -D__SYNTHESIS__ -D__HLS_SYN__ -I /opt/Xilinx/Vitis_HLS/2023.2/common/technology/autopilot -I /opt/Xilinx/Vitis_HLS/2023.2/common/technology/autopilot/ap_sysc -include etc/autopilot_ssdm_op.h -D__DSP48E2__ -I /usr/include/x86_64-linux-gnu -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp -hls-platform-db-name=/opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/common/platform.db -hls-platform-name=virtexuplus_medium -device-resource-info=BRAM_5376.000000_DSP_12288.000000_FF_3456000.000000_LUT_1728000.000000_SLICE_216000.000000_SLR_4.000000_URAM_1280.000000 -device-name-info=xcvu13p-flga2577-2-e > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.cpp.clang.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.cpp.clang.err.log
INFO-FLOW: Done: GCC PP 39 time: 0.6 seconds per iteration
INFO-FLOW: Source syntax check for synthesis
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang -foptimization-record-file=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/clang.diag.yml -mllvm -pass-remarks-missed=reflow|pasta|unroll -mllvm -pass-remarks=reflow|pasta|unroll|inline -fsyntax-only -fhls -target fpga64-xilinx-linux-gnu /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp -hls-platform-db-name=/opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/common/platform.db -hls-platform-name=virtexuplus_medium -device-resource-info=BRAM_5376.000000_DSP_12288.000000_FF_3456000.000000_LUT_1728000.000000_SLICE_216000.000000_SLR_4.000000_URAM_1280.000000 -device-name-info=xcvu13p-flga2577-2-e > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/clang.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/clang.err.log
WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:33:9)
WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:107:9)
WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:189:9)
Execute         clang_tidy xilinx-systemc-detector -desc systemc-detector /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp std=c++0x -target fpga  -directive=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/.systemc_flag 
INFO-FLOW: exec /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang-tidy -header-filter=.* --checks=-*,xilinx-systemc-detector -import-directive=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/.systemc_flag -fix-errors /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp -- -std=c++0x -target fpga -fhls -ferror-limit=0
Command         clang_tidy done; 3.74 sec.
INFO-FLOW: Running: clang-tidy CDT preprocess 39
Execute         clang_tidy xilinx-directive2pragma -desc directive2pragma /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp std=c++0x -target fpga  -directive=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/all.directive.json 
INFO-FLOW: exec /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang-tidy -header-filter=.* --checks=-*,xilinx-directive2pragma -import-directive=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/all.directive.json -fix-errors /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp -- -std=c++0x -target fpga -fhls -ferror-limit=0
Command         clang_tidy done; 4.26 sec.
INFO-FLOW: Done: clang-tidy CDT preprocess 39 time: 4.3 seconds per iteration
INFO-FLOW: Calling xilinx-label-all-loops ... 
INFO-FLOW: Calling xilinx-aggregate-on-hls-vector ... 
Execute         clang_tidy -errorcheck -desc loop-label xilinx-label-all-loops,xilinx-aggregate-on-hls-vector,,xilinx-warn-mayneed-no-ctor-attribute /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp std=c++0x -target fpga  
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang-tidy -export-fixes=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.clang-tidy.loop-label.diag.yml -header-filter=.* --checks=-*,xilinx-label-all-loops,xilinx-aggregate-on-hls-vector,,xilinx-warn-mayneed-no-ctor-attribute -fix-errors /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp -- -std=c++0x -target fpga -fhls -ferror-limit=0 > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.clang-tidy.loop-label.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.clang-tidy.loop-label.err.log
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/tps/tcl/tcllib1.11.1/yaml/yaml.tcl 
Command         clang_tidy done; 7.52 sec.
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/xilinx-dataflow-lawyer -export-fixes=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.xilinx-dataflow-lawyer.diag.yml /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp -- -std=c++0x -target fpga -fhls -ferror-limit=0 -fstrict-dataflow > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.xilinx-dataflow-lawyer.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.xilinx-dataflow-lawyer.err.log
Execute         ap_part_info -name xcvu13p-flga2577-2-e -data info 
INFO-FLOW: compiling source code to llvm bc
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang -foptimization-record-file=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.clang.diag.yml -mllvm -pass-remarks-missed=reflow|pasta|unroll -mllvm -pass-remarks=reflow|pasta|unroll|inline -fno-limit-debug-info -fhls -flto -fno-exceptions -Wno-error=c++11-narrowing -hls-emit-hint-scope /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp -std=c++0x -fno-math-errno -c -emit-llvm -mllvm -disable-llvm-optzns -Werror=implicit-function-declaration -Werror=implicit-hls-streams -Werror=return-type -Wpragmas -Wunused-parameter -Wdump-hls-pragmas -Wno-error=dump-hls-pragmas -hls-clock-period=5 -fno-threadsafe-statics -fno-use-cxa-atexit -target fpga64-xilinx-linux-gnu -D__VITIS_HLS__ -DAESL_SYN -D__SYNTHESIS__ -D__HLS_SYN__ -I /opt/Xilinx/Vitis_HLS/2023.2/common/technology/autopilot -I /opt/Xilinx/Vitis_HLS/2023.2/common/technology/autopilot/ap_sysc -include etc/autopilot_ssdm_op.h -D__DSP48E2__ -g -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.bc -hls-platform-db-name=/opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/common/platform.db -hls-platform-name=virtexuplus_medium -device-resource-info=BRAM_5376.000000_DSP_12288.000000_FF_3456000.000000_LUT_1728000.000000_SLICE_216000.000000_SLR_4.000000_URAM_1280.000000 -device-name-info=xcvu13p-flga2577-2-e > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.clang.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.pp.0.cpp.clang.err.log
WARNING: [HLS 207-5292] unused parameter 'keep' (firmware/nnet_utils/nnet_helpers.h:285:99)
WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:14:36)
WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_function_stubs.h:15:36)
WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_function_stubs.h:16:44)
WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:24:24)
WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_function_stubs.h:25:24)
WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_function_stubs.h:26:32)
WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:33:30)
WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:33:58)
WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:34:51)
WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:35:49)
WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:42:30)
WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:42:58)
WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:43:51)
WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:44:49)
WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:51:29)
WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:51:80)
WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:52:50)
WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:53:48)
WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_code_gen.h:16:39)
WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_code_gen.h:17:38)
WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_code_gen.h:18:60)
WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_code_gen.h:19:58)
INFO: [HLS 200-111] Finished Source Code Analysis and Preprocessing: CPU user time: 25.09 seconds. CPU system time: 1.67 seconds. Elapsed time: 27.65 seconds; current allocated memory: 263.203 MB.
INFO-FLOW: Linking Debug ...
INFO-FLOW: Linking dut bc code.
Execute         run_link_or_opt -out /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc -args  "/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.g.bc"  
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/llvm-link /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.g.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc.llvm-link.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc.llvm-link.err.log
INFO-FLOW: 
Execute         run_link_or_opt -opt -out /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.1.lower.bc -args /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc -reflow-lower-math-intrinsics 
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/opt -pass-remarks-missed=reflow|pasta|unroll -pass-remarks=reflow|pasta|unroll|inline -pass-remarks-output=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.1.lower.bc.opt.diag.yml /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc -reflow-lower-math-intrinsics -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.1.lower.bc > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.1.lower.bc.opt.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.1.lower.bc.opt.err.log
INFO-FLOW: 
INFO-FLOW: Running: gen_design_size_report post-opt
INFO-FLOW: Done: gen_design_size_report post-opt time: 0 seconds per iteration
Command         run_link_or_opt done; 0.34 sec.
INFO-FLOW: Linking math bc lib
Execute         run_link_or_opt -out /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.2.m1.bc -args /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.1.lower.bc -only-needed /opt/Xilinx/Vitis_HLS/2023.2/lnx64/lib/libhlsm_39.bc /opt/Xilinx/Vitis_HLS/2023.2/lnx64/lib/libhlsmc++_39.bc 
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/llvm-link /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.1.lower.bc -only-needed /opt/Xilinx/Vitis_HLS/2023.2/lnx64/lib/libhlsm_39.bc /opt/Xilinx/Vitis_HLS/2023.2/lnx64/lib/libhlsmc++_39.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.2.m1.bc > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.2.m1.bc.llvm-link.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.2.m1.bc.llvm-link.err.log
INFO-FLOW: 
Command         run_link_or_opt done; 1.73 sec.
Execute         run_link_or_opt -opt -out /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.3.fpc.bc -args /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.2.m1.bc -reflow-globaldce -hls-top-function-name=myproject -reflow-float-conversion 
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/opt -pass-remarks-missed=reflow|pasta|unroll -pass-remarks=reflow|pasta|unroll|inline -pass-remarks-output=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.3.fpc.bc.opt.diag.yml /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.2.m1.bc -reflow-globaldce -hls-top-function-name=myproject -reflow-float-conversion -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.3.fpc.bc > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.3.fpc.bc.opt.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.3.fpc.bc.opt.err.log
INFO-FLOW: 
INFO-FLOW: Running: gen_design_size_report post-opt
INFO-FLOW: Done: gen_design_size_report post-opt time: 0 seconds per iteration
Command         run_link_or_opt done; 0.82 sec.
Execute         run_link_or_opt -out /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.4.m2.bc -args /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.3.fpc.bc -only-needed /opt/Xilinx/Vitis_HLS/2023.2/lnx64/lib/libfloatconversion_39.bc 
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/llvm-link /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.3.fpc.bc -only-needed /opt/Xilinx/Vitis_HLS/2023.2/lnx64/lib/libfloatconversion_39.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.4.m2.bc > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.4.m2.bc.llvm-link.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.4.m2.bc.llvm-link.err.log
INFO-FLOW: 
Command         run_link_or_opt done; 0.15 sec.
Execute         run_link_or_opt -opt -out /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.5.gdce.bc -args /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.4.m2.bc -reflow-globaldce -hls-top-function-name=myproject 
INFO-FLOW: run_clang exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/opt -pass-remarks-missed=reflow|pasta|unroll -pass-remarks=reflow|pasta|unroll|inline -pass-remarks-output=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.5.gdce.bc.opt.diag.yml /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.4.m2.bc -reflow-globaldce -hls-top-function-name=myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.5.gdce.bc > /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.5.gdce.bc.opt.out.log 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.5.gdce.bc.opt.err.log
INFO-FLOW: 
INFO-FLOW: Running: gen_design_size_report post-opt
INFO-FLOW: Done: gen_design_size_report post-opt time: 0 seconds per iteration
Command         run_link_or_opt done; 0.16 sec.
Execute         send_msg_by_id INFO @200-777@%s Vivado 
INFO: [HLS 200-777] Using interface defaults for 'Vivado' flow target.
Execute         is_m_axi_addr64 
INFO-FLOW: Doing LTO.
INFO-FLOW: run_clang (background poll_ms 5000) exec: /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang -foptimization-record-file=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc.clang.reflow.diag.yml -mllvm -pass-remarks-missed=reflow|pasta|unroll -mllvm -pass-remarks=reflow|pasta|unroll|inline -fhls -mllvm -hls-top-function-name=myproject -mllvm -hls-db-dir -mllvm /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db -emit-llvm -c -target fpga64-xilinx-none -mllvm -xcl-xmlinfo=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/kernel.internal.xml -mllvm -top-io-mapping-info=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/top-io-fe.xml -mllvm -hls-bitcode-version=3.1 -mllvm -reflow-enable-slave-interface-default-setting=true -mllvm -gen-kernel-xml=false -mllvm -default-maxi-offset=slave -mllvm -maxi-latency=0 -mllvm -hls-maxi-data-size-in-bits=8 -mllvm -hls-maxi-max-data-size-in-bits=1024 -mllvm -hls-max-widen-size-in-bits=0 -mllvm -xcl-kernel-max-mem-ports=0 -mllvm -maxi-read-trans=16 -mllvm -maxi-write-trans=16 -mllvm -maxi-read-burst-len=16 -mllvm -maxi-write-burst-len=16 -mllvm -reflow-enable-saxi-64bits=0 -mllvm -reflow-basic-block-instr-threshold=200000 -mllvm -reflow-auto-pipeline-threshold=64 -mllvm -reflow-enable-maxi-auto-id-channel=0 -mllvm -enable-fp-thr=0 -mllvm -reflow-bdd-simplify-threshold=1048576 -mllvm -reflow-fanout-threshold=16 -mllvm -assume-maxi-align=1 -mllvm -reflow-pipeline-style-llvm-setting=2 -mllvm -reflow-enable-dataflow-strict-mode-checking=1 -ftime-report -mllvm -time-passes -mllvm -reflow-auto-array-partition-mode=default -mllvm -reflow-enable-auto-array-partition=true -mllvm -reflow-enable-auto-parallel-performance-driven=true -mllvm -reflow-enable-partition-for-automation=true -mllvm -reflow-aggregate-bitwidth-threshold=4096 -mllvm -reflow-reserved-saxilite-registers=0 -mllvm -enable-reflow-auto-loop-pipeline -mllvm -reflow-max-unroll-threshold=409600 -mllvm -reflow-assume-no-address-wrap=true -mllvm -reflow-enable-occurrence-inference=true -mllvm -reflow-emit-hint-scope=true -mllvm -hls -mllvm -disable-inlined-alloca-merging=true -mllvm -default-clock-period=5 -x ir /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.5.gdce.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.lto.bc -hls-platform-db-name=/opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/common/platform.db -hls-platform-name=virtexuplus_medium -device-resource-info=BRAM_5376.000000_DSP_12288.000000_FF_3456000.000000_LUT_1728000.000000_SLICE_216000.000000_SLR_4.000000_URAM_1280.000000 -device-name-info=xcvu13p-flga2577-2-e 2> /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.ld.0.bc.clang.reflow.err.log bg_poll_cmd: ::AP::poll_clang_39_closed_source
Execute         send_msg_by_id INFO @200-1995@%s%s%s 59,847 Compile/Link /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 59,847 instructions in the design after the 'Compile/Link' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 37,366 Unroll/Inline (step 1) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 37,366 instructions in the design after the 'Unroll/Inline (step 1)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 17,217 Unroll/Inline (step 2) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 17,217 instructions in the design after the 'Unroll/Inline (step 2)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 17,215 Unroll/Inline (step 3) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 17,215 instructions in the design after the 'Unroll/Inline (step 3)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 16,475 Unroll/Inline (step 4) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 16,475 instructions in the design after the 'Unroll/Inline (step 4)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 22,435 Array/Struct (step 1) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 22,435 instructions in the design after the 'Array/Struct (step 1)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 16,035 Array/Struct (step 2) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 16,035 instructions in the design after the 'Array/Struct (step 2)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 16,035 Array/Struct (step 3) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 16,035 instructions in the design after the 'Array/Struct (step 3)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 16,355 Array/Struct (step 4) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 16,355 instructions in the design after the 'Array/Struct (step 4)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 16,035 Array/Struct (step 5) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 16,035 instructions in the design after the 'Array/Struct (step 5)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 15,867 Performance (step 1) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 15,867 instructions in the design after the 'Performance (step 1)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 15,867 Performance (step 2) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 15,867 instructions in the design after the 'Performance (step 2)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 15,867 Performance (step 3) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 15,867 instructions in the design after the 'Performance (step 3)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 15,867 Performance (step 4) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 15,867 instructions in the design after the 'Performance (step 4)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 15,948 HW Transforms (step 1) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 15,948 instructions in the design after the 'HW Transforms (step 1)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
Execute         send_msg_by_id INFO @200-1995@%s%s%s 15,960 HW Transforms (step 2) /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt 
INFO: [HLS 200-1995] There were 15,960 instructions in the design after the 'HW Transforms (step 2)' phase of compilation. See the Design Size Report for more details: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth_design_size.rpt
INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0>, ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0> >::product(ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0>, ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0>)' into 'void nnet::layernorm_1d<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, config2::scale_t*, config2::bias_t*)' (firmware/nnet_utils/nnet_layernorm.h:91:11)
INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0>, ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0> >::product(ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0>, ap_fixed<14, 4, (ap_q_mode)4, (ap_o_mode)0, 0>)' into 'void nnet::layernorm_1d<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, config2::scale_t*, config2::bias_t*)' (firmware/nnet_utils/nnet_layernorm.h:83:12)
INFO: [HLS 214-291] Loop 'LAYERNORM_SEQ_LOOP' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_layernorm.h:122:5)
INFO: [HLS 214-291] Loop 'LAYERNORM_LOAD' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_layernorm.h:125:9)
INFO: [HLS 214-291] Loop 'LAYERNORM_STORE' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_layernorm.h:131:9)
INFO: [HLS 214-291] Loop 'LAYERNORM_1D_RESULT' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_layernorm.h:101:5)
INFO: [HLS 214-291] Loop 'LAYERNORM_1D_VAR' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_layernorm.h:86:5)
INFO: [HLS 214-291] Loop 'LAYERNORM_1D_SUM' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_layernorm.h:80:5)
INFO: [HLS 214-291] Loop 'VITIS_LOOP_30_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_transpose.h:30:22)
INFO: [HLS 214-291] Loop 'VITIS_LOOP_21_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_transpose.h:21:22)
INFO: [HLS 214-186] Unrolling loop 'LAYERNORM_SEQ_LOOP' (firmware/nnet_utils/nnet_layernorm.h:122:5) in function 'nnet::layernormalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 10 (firmware/nnet_utils/nnet_layernorm.h:109:0)
WARNING: [HLS 214-189] Pipeline directive for loop 'LAYERNORM_SEQ_LOOP' (firmware/nnet_utils/nnet_layernorm.h:122:5) in function 'nnet::layernormalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' has been removed because the loop is unrolled completely (firmware/nnet_utils/nnet_layernorm.h:109:0)
INFO: [HLS 214-186] Unrolling loop 'LAYERNORM_STORE' (firmware/nnet_utils/nnet_layernorm.h:131:9) in function 'nnet::layernormalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 8 (firmware/nnet_utils/nnet_layernorm.h:109:0)
INFO: [HLS 214-186] Unrolling loop 'LAYERNORM_LOAD' (firmware/nnet_utils/nnet_layernorm.h:125:9) in function 'nnet::layernormalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 8 (firmware/nnet_utils/nnet_layernorm.h:109:0)
INFO: [HLS 214-186] Unrolling loop 'LAYERNORM_1D_RESULT' (firmware/nnet_utils/nnet_layernorm.h:101:5) in function 'nnet::layernorm_1d<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 8 (firmware/nnet_utils/nnet_layernorm.h:51:0)
INFO: [HLS 214-186] Unrolling loop 'LAYERNORM_1D_VAR' (firmware/nnet_utils/nnet_layernorm.h:86:5) in function 'nnet::layernorm_1d<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 8 (firmware/nnet_utils/nnet_layernorm.h:51:0)
INFO: [HLS 214-186] Unrolling loop 'LAYERNORM_1D_SUM' (firmware/nnet_utils/nnet_layernorm.h:80:5) in function 'nnet::layernorm_1d<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 8 (firmware/nnet_utils/nnet_layernorm.h:51:0)
INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_30_1' (firmware/nnet_utils/nnet_transpose.h:30:22) in function 'nnet::transpose<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config4>' completely with a factor of 80 (firmware/nnet_utils/nnet_transpose.h:29:0)
INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_21_1' (firmware/nnet_utils/nnet_transpose.h:21:22) in function 'nnet::transfer_idx<config4>' completely with a factor of 2 (firmware/nnet_utils/nnet_transpose.h:18:0)
INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_30_1' (firmware/nnet_utils/nnet_transpose.h:30:22) in function 'nnet::transpose<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 80 (firmware/nnet_utils/nnet_transpose.h:29:0)
INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_21_1' (firmware/nnet_utils/nnet_transpose.h:21:22) in function 'nnet::transfer_idx<config3>' completely with a factor of 2 (firmware/nnet_utils/nnet_transpose.h:18:0)
INFO: [HLS 214-248] Applying array_partition to 'b2': Complete partitioning on dimension 1. (firmware/weights/b2.h:12:0)
INFO: [HLS 214-248] Applying array_partition to 's2': Complete partitioning on dimension 1. (firmware/weights/s2.h:12:0)
INFO: [HLS 214-248] Applying array_partition to 'in_val': Complete partitioning on dimension 1. (firmware/nnet_utils/nnet_layernorm.h:111:12)
INFO: [HLS 214-248] Applying array_partition to 'outval': Complete partitioning on dimension 1. (firmware/nnet_utils/nnet_layernorm.h:112:11)
INFO: [HLS 214-248] Applying array_partition to 'layer3_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:32:11)
INFO: [HLS 214-248] Applying array_partition to 'layer4_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:36:14)
INFO: [HLS 214-248] Applying array_partition to 'layer2_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:10:0)
INFO: [HLS 214-248] Applying array_reshape to 'input_1': Complete reshaping on dimension 1. (firmware/myproject.cpp:10:0)
INFO-FLOW: DBG:PUTS: copy_raw_kernel_xml ap_link_39: kernel.xml not generated: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/kernel.internal.xml
INFO: [HLS 200-111] Finished Compiling Optimization and Transform: CPU user time: 8.18 seconds. CPU system time: 0.6 seconds. Elapsed time: 13.76 seconds; current allocated memory: 263.938 MB.
INFO: [HLS 200-111] Finished Checking Pragmas: CPU user time: 0 seconds. CPU system time: 0 seconds. Elapsed time: 0 seconds; current allocated memory: 263.938 MB.
Execute         opt_and_import_c a -opt_level=2 -skip_syncheck=0 -ng=0 -keep_printf=0 
Execute           cleanup_all_models 
INFO: [HLS 200-10] Starting code transformations ...
INFO-FLOW: Running Standard Transforms...
Execute           transform -hls -share-std-xform -demangle-name -inline-byval-memcpy -always-inline -promote-dbg-pointer -interface-preproc -mem2reg -scalarrepl -mem2reg -keep-read-access -instcombine -dce -promote-dbg-pointer -bitop-raise -loop-simplify -indvarspre -indvars -loop-simplify -xunroll -constprop -instcombine -simplifycfg -indvars -simplifycfg -dce -globaldce -basicaa -simplifycfg -mem2reg -globalopt -global-constprop -deadargelim -instcombine -simplifycfg -scalarrepl -instcombine -reassociate -licm -simplifycfg -loop-simplify -indvars -instcombine -simplifycfg -mem2reg -loop-simplify -indvars -instcombine -gvn -gvn -instcombine -adce -break-crit-edges -simplifycfg -loop-delete -global-array-opt -dce -dse -adce -find-syn-modules -top myproject -deadargelim -mem2reg -instcombine -dce -presyn-prepare -interface-preproc -syn-check -check-rec-only -find-region -simplifycfg -func-extr -function-inline -globaldce -mem2reg -instcombine -dce -gvn -globaldce -adce -adse -constprop -instcombine -bit-constprop -instcombine -dce -simplifycfg -bitop-raise -simplifycfg -dce -loop-delete -reassociate -globalopt -global-privatize -mem2reg -dce -global-constprop -pointer-simplify -constprop -dce -auto-shift-reg-idiom -promote-dbg-pointer -norm-name /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.0.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.1.bc -f -phase std-opt 
Command           transform done; 0.3 sec.
INFO: [HLS 200-111] Finished Standard Transforms: CPU user time: 0.19 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.31 seconds; current allocated memory: 270.383 MB.
INFO: [HLS 200-10] Checking synthesizability ...
INFO-FLOW: Checking Synthesizability 1/2..
Execute           transform -hls -syn-check -check-rec-only -scalarrepl -norm-name -dce -mem2reg -instcombine -directive-preproc -mem2reg -dse -dce -dce -pag -array-normalize -instcombine -dce -array-seg-normalize -instcombine -dce -data-pack -instcombine -dce -inst-simplify -array-flatten -instcombine -dce -array-burst -dce -deadargelim -promote-global-argument -simplifycfg -mem2reg -globaldce -dce -deadargelim -dce -instcombine -function-inline -globaldce -dce -doublePtrSimplify -doublePtrElim -dce -doublePtrSimplify -promote-dbg-pointer -dce -scalarrepl -dse -adse -instcombine -ptrLegalization -simplifycfg -dce -instcombine -pointer-simplify -ptrArgReplace -dce -instcombine -resolve-double-ptr -scalarrepl -norm-name -dce -mem2reg -instcombine -ptrLegalization -simplifycfg -deadargelim -instcombine -dce -inst-simplify -directive-preproc -mem2reg -dse -dce -globaldce /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.1.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.2.prechk.bc -f 
Command           transform done; 0.23 sec.
INFO-FLOW: Checking Synthesizability 2/2..
Execute           transform -syn-check /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.2.prechk.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.2.bc -f -phase syn-check 
WARNING: [SYNCHK 200-23] firmware/nnet_utils/nnet_transpose.h:33: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability: CPU user time: 0.24 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.25 seconds; current allocated memory: 274.500 MB.
INFO-FLOW: Compiler optimizing ...
INFO-FLOW: Share syncheck's 1.bc for syn flow: copy /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.g.1.bc to /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.o.1.bc
INFO-FLOW: Presyn 1...
Execute           transform -hls -tmp /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db -interface-port-rename -directive-preproc -mem2reg -dse -dce -scalarrepl -norm-name -deadargelim -mem2reg -instcombine -dce -simplifycfg -dce -resource-proc -clib-intrinsic-prepare -dce -func-buffer -dce -pag -array-normalize -func-legal -instcombine -gvn -constprop -dce -simplifycfg -mem2reg -globaldce -resolve-double-ptr -dce -deadargelim -dce -instcombine -ptrArgReplace -mem2reg -dce -array-seg-normalize -deadargelim -instcombine -dce -directive-preproc -mem2reg -dse -dce -pointer-simplify -dce -port-alignment -dce -interface-preproc -data-pack -instcombine -dce -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -gvn -gvn -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -dse -adse -adce -loop-simplify -indvars -instcombine -gvn -loop-simplify -mem2reg -dce -find-region -instcombine -inst-simplify -interface-preproc -cfgopt -instcombine -indvars -auto-loop-unroll -loop-simplify -loop-bound -xunroll -constprop -instcombine -simplifycfg -indvars -simplifycfg -dce -globaldce -clean-region -attach-range -gvn -inst-simplify -constprop -simplifycfg -dce -pointer-simplify -dce -globalopt -constprop -dce -array-promote -scalar-auto-dep-elim -constprop -dce -ptrArgReplace -mem2reg -simplifycfg -dce -instcombine -dce -array-transform-check -array-reshape -instcombine -simplifycfg -dce -ptrArgReplace -deadargelim -mem2reg -instcombine -simplifycfg -dce -indvars -loop-simplify -loop-bound -xunroll -constprop -instcombine -simplifycfg -indvars -simplifycfg -dce -globaldce -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -dse -duplicate-dataflow-processes -globaldce -instcombine -array-partition -prepare-dynamic-array-partition -instcombine -simplifycfg -dce -ptrArgReplace -global-constprop -deadargelim -mem2reg -func-legal -dce -global-constprop -deadargelim -mem2reg -simplifycfg -dce -merge-param -deadargelim -globalopt -constprop -dce -array-promote -scalar-auto-dep-elim -constprop -dce -ptrArgReplace -mem2reg -simplifycfg -dce -mem-intrinsic-preproc -dce -global-internalize -global-privatize -mem2reg -globaldce -promote-global-argument -ptrArgReplace -mem2reg -dce -globalopt -mergereturn -simplify-global-access -mem2reg -dce -pointer-simplify -dce -functionattrs -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -gvn -gvn -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -dse -adse -adce -dce -norm-name -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -accesses-merge -function-inline -complex-op-raise -inst-simplify -globaldce -func-legal -dce -loop-bound -arraycheck -bitwidthmin2 -bitwidthmin2 -on-by-dataflow -loop-delete -instcombine -simplifycfg -globaldce -dce -gvn -deadargelim -dce -loop-simplify -clean-region -simplifycfg -propagate-stable-arguments -loop-stream -instcombine -simplifycfg -dce -globaldce -duplicate-dataflow-processes -stream-intrinsic-preproc -dce -check-ap-stream -loop-simplify -eliminate-keepreads -extract-dataflow-in-loop -loop-simplify -dce -gvn -deadargelim -dse -duplicate-dataflow-processes -check-dataflow-syntax -legalize-stream-variable -globaldce -legalize-global -extract-subproc -dce -dead-channel-elimination -canonicalize-gep -globaldce -dce -gvn -hls-dead-arg-elim -deadargelim -directive-preproc -canonicalize-dataflow -dce -globaldce -scalar-preprocessing -scalar-propagation2 -scalar-stream -deadargelim -globaldce -mem2reg -check-dataflow-channels -function-stream -dce -globaldce -prop-fifo-spec -internal-stream-gen -canonicalize-gep -globaldce -dce -gvn -deadargelim -mergereturn -indvars -loop-simplify -instcombine -array-stream -array-seg-normalize -array-partition -clean-array-spec -func-legal -instcombine -simplifycfg -dce -bundle-memfifo-ops -deadargelim -directive-preproc -mem2reg -dse -dce -group-axi-access -licm -simplifycfg -dce -loop-delete -hls-display -norm-name /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.o.1.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.o.1.tmp.bc -f 
Command           transform done; 0.56 sec.
INFO-FLOW: Presyn 2...
Execute           transform -hls -keep-callgraph -scalarrepl -mem2reg -port-alignment -attach-range -dce -pipe-mux-gen -indvars -loop-bound -inst-simplify -instcombine -dce -merge-array-access -mem2reg -dce -clean-region -mergereturn -if-conv -instcombine -dce -constprop -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -gvn -gvn -basicaa -aggr-aa -aggrmodref-aa -aggr-aa -dse -adse -adce -scalarrepl -mem2reg -global-constprop -deadargelim -deadargelim -instcombine -dce -simplifycfg -ptrArgReplace -mem2reg -function-inline -globaldce -mem2reg -instcombine -dce -expr-balance -instcombine -dce -bitwidthmin2 -bitwidthmin2 -interface-preproc -directive-preproc -inst-rectify -instcombine -dce -functionattrs -constprop -instcombine -bit-constprop -simplify-global-access -globalopt -globaldce -inst-simplify -instcombine -elimdeaddata -dce -loop-delete -simplifycfg -loop-simplify -barrier -norm-name /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.o.1.tmp.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.o.2.bc -f -phase presyn 
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_layernorm.h:81:22) to (firmware/nnet_utils/nnet_layernorm.h:104:1) in function 'nnet::layernorm_1d<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>'... converting 21 basic blocks.
Command           transform done; 0.21 sec.
INFO: [HLS 200-111] Finished Loop, function and other optimizations: CPU user time: 0.76 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.77 seconds; current allocated memory: 304.527 MB.
INFO-FLOW: Building ssdm...
Execute           transform -hls -auto-function-inline -globaldce -ptrArgReplace -mem2reg -dce -reset-lda -loop-simplify -indvars -aggr-aa -licm -loop-dep -loop-bound -licm -loop-simplify -loop-sink-hoist -flattenloopnest -array-flatten -gvn -instcombine -dce -array-map -dce -func-legal -gvn -adce -instcombine -cfgopt -simplifycfg-lite -loop-simplify -array-burst -promote-global-argument -dce -array-seg-normalize -basicaa -aggrmodref-aa -globalsmodref-aa -aggr-aa -gvn -gvn -basicaa -aggrmodref-aa -globalsmodref-aa -aggr-aa -dse -adse -adce -licm -inst-simplify -dce -globaldce -instcombine -array-stream -eliminate-keepreads -instcombine -dce -deadargelim -doublePtrSimplify -doublePtrElim -dce -doublePtrSimplify -promote-dbg-pointer -dce -scalarrepl -mem2reg -norm-name -mem2reg -instcombine -dse -adse -adce -ptrLegalization -dce -array-flatten -dce -instcombine -check-doubleptr -loop-rot -constprop -cfgopt -simplifycfg-lite -loop-simplify -indvars -pointer-simplify -dce -loop-bound -loop-simplify -loop-preproc -constprop -global-constprop -gvn -mem2reg -instcombine -dce -loop-bound -loop-merge -dce -deadargelim -dce -canonicalize-dataflow -dce -deadargelim -globaldce -mem2reg -bram-byte-enable -inst-simplify -inst-rectify -instcombine -adce -deadargelim -load-elim -read-loop-dep -loop-simplify -loop-extract-inner -directive-preproc -bitwidthmin2 -bitwidthmin2 -read-loop-dep -interface-preproc -directive-preproc -interface-gen -bram-byte-enable-spec-prop -deadargelim -inst-simplify -dce -mem2reg -instcombine -gvn -dce -adse -loop-bound -instcombine -cfgopt -simplifycfg-lite -loop-simplify -clean-region -io-protocol -find-region -mem2reg -bitop-raise -complex-op-raise -inst-simplify -inst-rectify -instcombine -adce -deadargelim -float-op-raise -loop-simplify -phi-opt -bitop-raise -cfgopt -simplifycfg-lite -strip-dead-prototypes -interface-lower -bitop-lower -intrinsic-lower -auto-function-inline -basicaa -aggrmodref-aa -globalsmodref-aa -aggr-aa -inst-simplify -simplifycfg-lite -loop-simplify -mergereturn -inst-simplify -inst-rectify -globaldce -dce -load-elim -bitop-lower -float-op-raise -fma-raise -loop-rewind -pointer-simplify -dce -cfgopt -dce -loop-bound -loop-dep -read-loop-dep -dce -dyn-mem-reuse -dce -recurrence-min -dce -share-scalar-alloca -deadargelim -dce -check-stream -norm-name -legalize -validate-dataflow -inst-clarity -bitwidth -dce -dump-loop-dep-to-ir -check-all-ssdm -dump-complexity-metric -cdfg-build /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.o.2.bc -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/a.o.3.bc -f -phase build-ssdm 
INFO: [XFORM 203-603] Evaluating the output(s) of a call to function 'nnet::transfer_idx<config4>' (firmware/nnet_utils/nnet_transpose.h:32:6) in function 'nnet::transpose<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config4>' and propagating its result(s) since all actual argument(s) to the function are constants.
INFO: [XFORM 203-603] Evaluating the output(s) of a call to function 'nnet::transfer_idx<config3>' (firmware/nnet_utils/nnet_transpose.h:32:12) in function 'nnet::transpose<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' and propagating its result(s) since all actual argument(s) to the function are constants.
Execute             auto_get_db
Command           transform done; 0.32 sec.
INFO: [HLS 200-111] Finished Architecture Synthesis: CPU user time: 0.3 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.33 seconds; current allocated memory: 348.980 MB.
INFO-FLOW: Finish building internal data model.
Command         opt_and_import_c done; 1.66 sec.
Command       elaborate done; 43.08 sec.
Execute       ap_eval exec zip -j /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/dut.hcp $dbDir/a.o.3.bc $dbDir/${topname}.rtl_wrap.cfg.tcl $dbDir/apatb_${topname}.cpp $dbDir/apatb_${topname}_util.cpp $dbDir/apatb_${topname}_ir.ll $dbDir/mapper_${topname}.cpp $dbDir/top-io-fe.xml $dbDir/kernel.internal.xml $workdir/../hls.app 
Execute       autosyn -from_csynth_design=1 
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO-FLOW: Synthesizing C/C++ design ...
INFO: [HLS 200-10] Synthesizing 'myproject' ...
Execute         ap_set_top_model myproject 
WARNING: [SYN 201-103] Legalizing function name 'transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>' to 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s'.
WARNING: [SYN 201-103] Legalizing function name 'transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>' to 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s'.
WARNING: [SYN 201-103] Legalizing function name 'layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>' to 'layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s'.
WARNING: [SYN 201-103] Legalizing function name 'layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>' to 'layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s'.
Execute         get_model_list myproject -filter all-wo-channel -topdown 
Execute         preproc_iomode -model myproject 
Execute         preproc_iomode -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         preproc_iomode -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         preproc_iomode -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
Execute         preproc_iomode -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
Execute         get_model_list myproject -filter all-wo-channel 
INFO-FLOW: Model list for configure: {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>} {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>} {layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} {layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} myproject
INFO-FLOW: Configuring Module : transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> ...
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
Execute         apply_spec_resource_limit transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
INFO-FLOW: Configuring Module : transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> ...
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
Execute         apply_spec_resource_limit transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
INFO-FLOW: Configuring Module : layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> ...
Execute         set_default_model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         apply_spec_resource_limit layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO-FLOW: Configuring Module : layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> ...
Execute         set_default_model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         apply_spec_resource_limit layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO-FLOW: Configuring Module : myproject ...
Execute         set_default_model myproject 
Execute         apply_spec_resource_limit myproject 
INFO-FLOW: Model list for preprocess: {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>} {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>} {layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} {layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} myproject
INFO-FLOW: Preprocessing Module: transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> ...
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
Execute         cdfg_preprocess -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
Execute         rtl_gen_preprocess transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
INFO-FLOW: Preprocessing Module: transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> ...
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
Execute         cdfg_preprocess -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
Execute         rtl_gen_preprocess transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
INFO-FLOW: Preprocessing Module: layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> ...
Execute         set_default_model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         cdfg_preprocess -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         rtl_gen_preprocess layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO-FLOW: Preprocessing Module: layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> ...
Execute         set_default_model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         cdfg_preprocess -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         rtl_gen_preprocess layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO-FLOW: Preprocessing Module: myproject ...
Execute         set_default_model myproject 
Execute         cdfg_preprocess -model myproject 
Execute         rtl_gen_preprocess myproject 
INFO-FLOW: Model list for synthesis: {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>} {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>} {layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} {layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} myproject
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
Execute         schedule -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>'.
INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>'
INFO: [SCHED 204-11] Finished scheduling.
Command         schedule done; 0.13 sec.
INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.13 seconds. CPU system time: 0.03 seconds. Elapsed time: 0.2 seconds; current allocated memory: 350.152 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.verbose.sched.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.sched.adb -f 
INFO-FLOW: Finish scheduling transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>.
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
Execute         bind -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.05 seconds; current allocated memory: 350.523 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.verbose.bind.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.bind.adb -f 
INFO-FLOW: Finish binding transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
Execute         schedule -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>'.
INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>'
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.11 seconds. CPU system time: 0 seconds. Elapsed time: 0.11 seconds; current allocated memory: 351.699 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.verbose.sched.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.sched.adb -f 
INFO-FLOW: Finish scheduling transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>.
Execute         set_default_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
Execute         bind -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111] Finished Binding: CPU user time: 0.02 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 351.707 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.verbose.bind.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.bind.adb -f 
INFO-FLOW: Finish binding transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         set_default_model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         schedule -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>'.
INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 9, function 'layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>'
INFO: [SCHED 204-11] Finished scheduling.
Command         schedule done; 0.48 sec.
INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.49 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.5 seconds; current allocated memory: 362.043 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.verbose.sched.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.sched.adb -f 
INFO-FLOW: Finish scheduling layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>.
Execute         set_default_model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         bind -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111] Finished Binding: CPU user time: 0.09 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.09 seconds; current allocated memory: 362.043 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.verbose.bind.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.bind.adb -f 
INFO-FLOW: Finish binding layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         set_default_model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         schedule -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>'.
INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 9, function 'layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>'
INFO: [SCHED 204-11] Finished scheduling.
Command         schedule done; 0.13 sec.
INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.2 seconds. CPU system time: 0 seconds. Elapsed time: 0.21 seconds; current allocated memory: 362.145 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.verbose.sched.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.sched.adb -f 
INFO-FLOW: Finish scheduling layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>.
Execute         set_default_model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         bind -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111] Finished Binding: CPU user time: 0.05 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.05 seconds; current allocated memory: 362.145 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.verbose.bind.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.bind.adb -f 
INFO-FLOW: Finish binding layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'myproject' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         set_default_model myproject 
Execute         schedule -model myproject 
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'myproject'.
INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 9, function 'myproject'
INFO: [SCHED 204-11] Finished scheduling.
Command         schedule done; 0.16 sec.
INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.22 seconds. CPU system time: 0 seconds. Elapsed time: 0.23 seconds; current allocated memory: 365.188 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.verbose.sched.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.sched.adb -f 
INFO-FLOW: Finish scheduling myproject.
Execute         set_default_model myproject 
Execute         bind -model myproject 
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111] Finished Binding: CPU user time: 0.07 seconds. CPU system time: 0 seconds. Elapsed time: 0.07 seconds; current allocated memory: 365.188 MB.
Execute         syn_report -verbosereport -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.verbose.bind.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.bind.adb -f 
INFO-FLOW: Finish binding myproject.
Execute         get_model_list myproject -filter all-wo-channel 
INFO-FLOW: Preprocessing for RTLGen ...
Execute         rtl_gen_preprocess transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> 
Execute         rtl_gen_preprocess transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> 
Execute         rtl_gen_preprocess layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         rtl_gen_preprocess layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> 
Execute         rtl_gen_preprocess myproject 
INFO-FLOW: Model list for RTL generation: {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>} {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>} {layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} {layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} myproject
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         create_rtl_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -top_prefix myproject_ -sub_prefix myproject_ -mg_file /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.compgen.tcl 
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s'.
Command         create_rtl_model done; 0.19 sec.
INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.24 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.26 seconds; current allocated memory: 387.891 MB.
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute         gen_rtl transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -style xilinx -f -lang vhdl -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/vhdl/myproject_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s 
Execute         gen_rtl transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -style xilinx -f -lang vlog -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/verilog/myproject_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s 
Execute         syn_report -csynth -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s_csynth.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -rtlxml -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s_csynth.xml 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -verbosereport -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.verbose.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -f -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.adb 
Execute         db_write -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -bindview -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/design.bindinfo.xml 
Execute         gen_tb_info transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3> -p /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         create_rtl_model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -top_prefix myproject_ -sub_prefix myproject_ -mg_file /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.compgen.tcl 
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s'.
Command         create_rtl_model done; 0.16 sec.
INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.23 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.25 seconds; current allocated memory: 407.156 MB.
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute         gen_rtl transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -style xilinx -f -lang vhdl -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/vhdl/myproject_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s 
Execute         gen_rtl transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -style xilinx -f -lang vlog -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/verilog/myproject_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s 
Execute         syn_report -csynth -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s_csynth.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -rtlxml -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s_csynth.xml 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -verbosereport -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.verbose.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -f -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.adb 
Execute         db_write -model transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -bindview -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/design.bindinfo.xml 
Execute         gen_tb_info transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4> -p /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         create_rtl_model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -top_prefix myproject_ -sub_prefix myproject_ -mg_file /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.compgen.tcl 
INFO: [SYN 201-210] Renamed object name 'layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_table_ROM_AUTO_1R' to 'layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb' due to the length limit 80
INFO: [HLS 200-1030] Apply Unified Pipeline Control on module 'layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' pipeline 'layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>' pipeline type 'function pipeline'
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_22s_10ns_20ns_32_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_22s_10ns_20s_32_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_22s_10ns_21s_32_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_22s_11ns_17ns_33_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_22s_11ns_18ns_33_1_1': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mac_muladd_22s_11ns_21s_33_1_1': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_14s_14s_28_1_1': 8 instance(s).
INFO: [RTGEN 206-100] Generating core module 'mul_14s_8ns_22_1_1': 8 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s'.
INFO: [RTMG 210-279] Implementing memory 'myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb' using auto ROMs.
Command         create_rtl_model done; 0.15 sec.
INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.21 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.23 seconds; current allocated memory: 410.688 MB.
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute         gen_rtl layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -style xilinx -f -lang vhdl -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/vhdl/myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s 
Execute         gen_rtl layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -style xilinx -f -lang vlog -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/verilog/myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s 
Execute         syn_report -csynth -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_csynth.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -rtlxml -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_csynth.xml 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -verbosereport -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.verbose.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -f -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.adb 
Execute         db_write -model layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -bindview -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/design.bindinfo.xml 
Execute         gen_tb_info layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -p /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         create_rtl_model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -top_prefix myproject_ -sub_prefix myproject_ -mg_file /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.compgen.tcl 
INFO: [HLS 200-1030] Apply Unified Pipeline Control on module 'layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' pipeline 'layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>' pipeline type 'function pipeline'
INFO: [RTGEN 206-100] Finished creating RTL model for 'layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s'.
Command         create_rtl_model done; 0.28 sec.
INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.57 seconds. CPU system time: 0.04 seconds. Elapsed time: 0.62 seconds; current allocated memory: 448.441 MB.
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute         gen_rtl layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -style xilinx -f -lang vhdl -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/vhdl/myproject_layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s 
Execute         gen_rtl layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -style xilinx -f -lang vlog -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/verilog/myproject_layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s 
Execute         syn_report -csynth -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_csynth.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -rtlxml -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_csynth.xml 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -verbosereport -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.verbose.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -f -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.adb 
Execute         db_write -model layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -bindview -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/design.bindinfo.xml 
Execute         gen_tb_info layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2> -p /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'myproject' 
INFO: [HLS 200-10] ----------------------------------------------------------------
Execute         create_rtl_model myproject -top_prefix  -sub_prefix myproject_ -mg_file /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.compgen.tcl 
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/input_1' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_0' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_1' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_2' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_3' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_4' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_5' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_6' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_7' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_8' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_9' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_10' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_11' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_12' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_13' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_14' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_15' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_16' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_17' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_18' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_19' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_20' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_21' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_22' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_23' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_24' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_25' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_26' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_27' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_28' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_29' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_30' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_31' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_32' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_33' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_34' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_35' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_36' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_37' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_38' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_39' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_40' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_41' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_42' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_43' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_44' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_45' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_46' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_47' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_48' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_49' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_50' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_51' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_52' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_53' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_54' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_55' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_56' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_57' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_58' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_59' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_60' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_61' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_62' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_63' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_64' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_65' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_66' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_67' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_68' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_69' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_70' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_71' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_72' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_73' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_74' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_75' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_76' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_77' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_78' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer2_out_79' to 'ap_vld'.
INFO: [RTGEN 206-500] Setting interface mode on function 'myproject' to 'ap_ctrl_hs'.
INFO: [HLS 200-1030] Apply Unified Pipeline Control on module 'myproject' pipeline 'myproject' pipeline type 'function pipeline'
INFO: [RTGEN 206-104] Estimated max fanout for 'myproject' is 17290 from HDL expression: ((1'b0 == ap_block_pp0_stage0_11001_ignoreCallOp173) & (1'b1 == ap_CS_fsm_pp0_stage0))
INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject'.
Command         create_rtl_model done; 0.61 sec.
INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.71 seconds. CPU system time: 0.06 seconds. Elapsed time: 0.77 seconds; current allocated memory: 486.371 MB.
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute         gen_rtl myproject -istop -style xilinx -f -lang vhdl -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/vhdl/myproject 
Execute         gen_rtl myproject -istop -style xilinx -f -lang vlog -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/verilog/myproject 
Execute         syn_report -csynth -model myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/myproject_csynth.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -rtlxml -model myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/myproject_csynth.xml 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -verbosereport -model myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.verbose.rpt 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         db_write -model myproject -f -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.adb 
Execute         db_write -model myproject -bindview -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/design.bindinfo.xml 
Execute         gen_tb_info myproject -p /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject 
Execute         export_constraint_db -f -tool general -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.constraint.tcl 
Execute         syn_report -designview -model myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.design.xml 
Execute         syn_report -csynthDesign -model myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth.rpt -MHOut /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/kernel_module_hierarchy.tcl 
Execute           list_part -family xcvu13p-flga2577-2-e 
Execute             ap_family_info -name xcvu13p-flga2577-2-e -data names 
Execute             ap_part_info -quiet -name xcvu13p-flga2577-2-e -data family 
Execute         syn_report -wcfg -model myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject_dataflow_ana.wcfg 
Execute         syn_report -protoinst -model myproject -o /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.protoinst 
Execute         sc_get_clocks myproject 
Execute         sc_get_portdomain myproject 
INFO-FLOW: Model list for RTL component generation: {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>} {transpose<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config4>} {layernorm_1d<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} {layernormalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>} myproject
INFO-FLOW: Handling components in module [transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s] ... 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.compgen.tcl 
INFO-FLOW: Handling components in module [transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s] ... 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.compgen.tcl 
INFO-FLOW: Handling components in module [layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s] ... 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.compgen.tcl 
INFO-FLOW: Found component myproject_mul_14s_14s_28_1_1.
INFO-FLOW: Append model myproject_mul_14s_14s_28_1_1
INFO-FLOW: Found component myproject_mul_14s_8ns_22_1_1.
INFO-FLOW: Append model myproject_mul_14s_8ns_22_1_1
INFO-FLOW: Found component myproject_mac_muladd_22s_11ns_21s_33_1_1.
INFO-FLOW: Append model myproject_mac_muladd_22s_11ns_21s_33_1_1
INFO-FLOW: Found component myproject_mac_muladd_22s_10ns_20s_32_1_1.
INFO-FLOW: Append model myproject_mac_muladd_22s_10ns_20s_32_1_1
INFO-FLOW: Found component myproject_mac_muladd_22s_11ns_18ns_33_1_1.
INFO-FLOW: Append model myproject_mac_muladd_22s_11ns_18ns_33_1_1
INFO-FLOW: Found component myproject_mac_muladd_22s_10ns_21s_32_1_1.
INFO-FLOW: Append model myproject_mac_muladd_22s_10ns_21s_32_1_1
INFO-FLOW: Found component myproject_mac_muladd_22s_10ns_20ns_32_1_1.
INFO-FLOW: Append model myproject_mac_muladd_22s_10ns_20ns_32_1_1
INFO-FLOW: Found component myproject_mac_muladd_22s_11ns_17ns_33_1_1.
INFO-FLOW: Append model myproject_mac_muladd_22s_11ns_17ns_33_1_1
INFO-FLOW: Found component myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb.
INFO-FLOW: Append model myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb
INFO-FLOW: Handling components in module [layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s] ... 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.compgen.tcl 
INFO-FLOW: Handling components in module [myproject] ... 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.compgen.tcl 
INFO-FLOW: Append model transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s
INFO-FLOW: Append model transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s
INFO-FLOW: Append model layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
INFO-FLOW: Append model layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
INFO-FLOW: Append model myproject
INFO-FLOW: Generating RTL model list ...
INFO-FLOW: All models in this session: myproject_mul_14s_14s_28_1_1 myproject_mul_14s_8ns_22_1_1 myproject_mac_muladd_22s_11ns_21s_33_1_1 myproject_mac_muladd_22s_10ns_20s_32_1_1 myproject_mac_muladd_22s_11ns_18ns_33_1_1 myproject_mac_muladd_22s_10ns_21s_32_1_1 myproject_mac_muladd_22s_10ns_20ns_32_1_1 myproject_mac_muladd_22s_11ns_17ns_33_1_1 myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s myproject
INFO-FLOW: Generating /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/autopilot.rtl.models.txt file...
INFO-FLOW: To file: write model myproject_mul_14s_14s_28_1_1
INFO-FLOW: To file: write model myproject_mul_14s_8ns_22_1_1
INFO-FLOW: To file: write model myproject_mac_muladd_22s_11ns_21s_33_1_1
INFO-FLOW: To file: write model myproject_mac_muladd_22s_10ns_20s_32_1_1
INFO-FLOW: To file: write model myproject_mac_muladd_22s_11ns_18ns_33_1_1
INFO-FLOW: To file: write model myproject_mac_muladd_22s_10ns_21s_32_1_1
INFO-FLOW: To file: write model myproject_mac_muladd_22s_10ns_20ns_32_1_1
INFO-FLOW: To file: write model myproject_mac_muladd_22s_11ns_17ns_33_1_1
INFO-FLOW: To file: write model myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb
INFO-FLOW: To file: write model transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s
INFO-FLOW: To file: write model transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s
INFO-FLOW: To file: write model layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
INFO-FLOW: To file: write model layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
INFO-FLOW: To file: write model myproject
INFO-FLOW: Generating /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/autopilot.rtl.models.tcl file...
INFO-FLOW: Finished generating RTL model list.


INFO-FLOW: RTL Generation done.
INFO-FLOW: CAS Generation done.
INFO-FLOW: CBC Generation done.
INFO-FLOW: DBG:PROC: ::AESL_AUTOMG::auto_generate_csynth_design
INFO-FLOW: DBG:PUTS: read_platform_lib /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/common.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/APCoreGen.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/op.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/op_simcore.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/interface.gen 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/common/xilinx.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/plb46.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/axi4.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/nativeAXI4.gen 
Execute             source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/saxilite.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/scripts/xilinxcoregen.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/XilEDKCoreGen.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/dds_compiler.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/util.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/xfft.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/xfir.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/DSP48/dsp48.gen 
INFO-FLOW: DBG:PUTS:   using AESL_AUTOCG::g_clock_period=5.000 (was NA)
INFO-FLOW: DBG:PROC: ::AESL_AUTOMG::generate_ip_cores gen_sim_model='1' gen_fp_models='0' gen_for_export='0' dstSCDir='' dstVhdlDir='/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/vhdl' dstVlogDir='/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/vlog' tclDir='/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db' modelList='myproject_mul_14s_14s_28_1_1
myproject_mul_14s_8ns_22_1_1
myproject_mac_muladd_22s_11ns_21s_33_1_1
myproject_mac_muladd_22s_10ns_20s_32_1_1
myproject_mac_muladd_22s_11ns_18ns_33_1_1
myproject_mac_muladd_22s_10ns_21s_32_1_1
myproject_mac_muladd_22s_10ns_20ns_32_1_1
myproject_mac_muladd_22s_11ns_17ns_33_1_1
myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb
transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s
transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s
layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
myproject
' expOnly='0'
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute         ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute         ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.compgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.compgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.compgen.tcl 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute           ap_part_info -name xcvu13p-flga2577-2-e -data info 
Command         ap_source done; 0.22 sec.
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.compgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.compgen.tcl 
INFO: [HLS 200-111] Finished Generating all RTL models: CPU user time: 0.53 seconds. CPU system time: 0.05 seconds. Elapsed time: 0.59 seconds; current allocated memory: 487.008 MB.
INFO-FLOW: DBG:PROC: ::HLSREPORTS::create_csynth_xml bind_info_var='bind_info' RtlSubPrefix='myproject_' outfile=''
INFO-FLOW: Running: create_csynth_xml read xml data
INFO-FLOW: Done: create_csynth_xml read xml data time: 0 seconds per iteration
INFO-FLOW: Running: create_csynth_xml bind info
INFO-FLOW: No bind nodes found for module_name transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s
INFO-FLOW: No bind nodes found for module_name transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s
INFO-FLOW: No bind nodes found for module_name layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
INFO-FLOW: No bind nodes found for module_name myproject
INFO-FLOW: Done: create_csynth_xml bind info time: 0 seconds per iteration
INFO-FLOW: Running: create_csynth_xml config info
INFO-FLOW: Done: create_csynth_xml config info time: 0.1 seconds per iteration
INFO-FLOW: Running: create_csynth_xml write xml
INFO-FLOW: Done: create_csynth_xml write xml time: 0 seconds per iteration
INFO-FLOW: DBG:PUTS:      create_csynth_xml wrote csynth_xml=/data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/syn/report/csynth.xml
INFO-FLOW: DBG:PROC: ::AP::DESIGN_DATA::generate_json generate_bd_files='0' generate_xo_files='0' modelList='myproject_mul_14s_14s_28_1_1
myproject_mul_14s_8ns_22_1_1
myproject_mac_muladd_22s_11ns_21s_33_1_1
myproject_mac_muladd_22s_10ns_20s_32_1_1
myproject_mac_muladd_22s_11ns_18ns_33_1_1
myproject_mac_muladd_22s_10ns_21s_32_1_1
myproject_mac_muladd_22s_10ns_20ns_32_1_1
myproject_mac_muladd_22s_11ns_17ns_33_1_1
myproject_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_invert_sqr_tabkb
transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s
transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s
layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s
myproject
' rtl_lang='both' bootstrap_tcl='false' outdir='' outfilename=''
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/top-io-be.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.compgen.dataonly.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s.tbgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s.tbgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.tbgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s.tbgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute         ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute         ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.constraint.tcl 
Execute         sc_get_clocks myproject 
Execute         source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
INFO-FLOW: DBG:PROC: ::HLSREPORTS::add_csynth_report_sections bind_info_dict='adapter_nodes {} report_dict {TOPINST myproject MODULE2INSTS {myproject myproject transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s call_ret9_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s_fu_758 transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s call_ret_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s_fu_764 layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_848 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s {grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_648 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_670 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_692 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_714 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_736 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_758 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_780 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_802 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_824 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_846}} INST2MODULE {myproject myproject call_ret9_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s_fu_758 transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s call_ret_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s_fu_764 transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s grp_layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_848 layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_648 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_670 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_692 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_714 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_736 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_758 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_780 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_802 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_824 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_846 layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s} INSTDATA {myproject {DEPTH 1 CHILDREN {call_ret9_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s_fu_758 call_ret_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s_fu_764 grp_layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_848}} call_ret9_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s_fu_758 {DEPTH 2 CHILDREN {}} call_ret_transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s_fu_764 {DEPTH 2 CHILDREN {}} grp_layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_848 {DEPTH 2 CHILDREN {grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_648 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_670 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_692 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_714 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_736 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_758 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_780 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_802 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_824 grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_846}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_648 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_670 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_692 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_714 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_736 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_758 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_780 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_802 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_824 {DEPTH 3 CHILDREN {}} grp_layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s_fu_846 {DEPTH 3 CHILDREN {}}} MODULEDATA {layernorm_1d_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s {BINDINFO {{BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln81_fu_419_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:81 VARIABLE add_ln81 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln81_1_fu_587_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:81 VARIABLE add_ln81_1 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln81_2_fu_755_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:81 VARIABLE add_ln81_2 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln81_3_fu_923_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:81 VARIABLE add_ln81_3 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln81_4_fu_1285_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:81 VARIABLE add_ln81_4 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln81_5_fu_1352_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:81 VARIABLE add_ln81_5 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln81_6_fu_1419_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:81 VARIABLE add_ln81_6 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln83_fu_1551_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:83 VARIABLE add_ln83 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_fu_1612_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U82 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_fu_2161_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_1_fu_1671_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87_1 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U83 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88_1 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_1_fu_2414_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88_1 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME sum_cache2_1_fu_3355_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE sum_cache2_1 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln89_fu_3359_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE add_ln89 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_2_fu_1730_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87_2 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U84 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88_2 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_2_fu_2667_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88_2 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME sum_cache2_3_fu_3422_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE sum_cache2_3 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln89_1_fu_3427_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE add_ln89_1 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_3_fu_1789_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87_3 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U85 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88_3 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_3_fu_2920_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88_3 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME sum_cache2_5_fu_3490_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE sum_cache2_5 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln89_2_fu_3495_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE add_ln89_2 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_4_fu_1848_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87_4 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U86 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88_4 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_4_fu_3173_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88_4 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME sum_cache2_7_fu_3558_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE sum_cache2_7 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln89_3_fu_3563_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE add_ln89_3 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_5_fu_1907_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87_5 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U87 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88_5 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_5_fu_3662_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88_5 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME sum_cache2_9_fu_4380_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE sum_cache2_9 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln89_4_fu_4385_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE add_ln89_4 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_6_fu_1966_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87_6 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U88 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88_6 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_6_fu_3915_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88_6 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME sum_cache2_11_fu_4448_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE sum_cache2_11 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln89_5_fu_4453_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE add_ln89_5 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE sub PRAGMA {} RTLNAME sub_ln87_7_fu_2025_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:87 VARIABLE sub_ln87_7 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op sub}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_14s_28_1_1_U89 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE mul_ln88_7 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln88_7_fu_4168_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:88 VARIABLE add_ln88_7 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME sum_cache2_13_fu_4516_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE sum_cache2_13 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln89_6_fu_4521_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:89 VARIABLE add_ln89_6 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL fabric LATENCY 0 OPTYPE add PRAGMA {} RTLNAME add_ln91_fu_4645_p2 SOURCE firmware/nnet_utils/nnet_layernorm.h:91 VARIABLE add_ln91 LOOP {} BUNDLEDNAME {} DSP 0 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U90 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_11ns_21s_33_1_1_U98 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_1 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_11ns_21s_33_1_1_U98 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U91 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_2 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_10ns_20s_32_1_1_U99 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_3 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_10ns_20s_32_1_1_U99 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102_1 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U92 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_4 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_10ns_20s_32_1_1_U100 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_5 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_10ns_20s_32_1_1_U100 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102_2 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U93 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_6 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_11ns_18ns_33_1_1_U101 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_7 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_11ns_18ns_33_1_1_U101 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102_3 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U94 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_8 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_10ns_21s_32_1_1_U102 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_9 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_10ns_21s_32_1_1_U102 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102_4 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U95 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_10 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_10ns_20ns_32_1_1_U103 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_11 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_10ns_20ns_32_1_1_U103 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102_5 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U96 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_12 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_11ns_21s_33_1_1_U104 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_13 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_11ns_21s_33_1_1_U104 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102_6 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE op ID {} IMPL auto LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mul_14s_8ns_22_1_1_U97 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_14 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE mul PRAGMA {} RTLNAME mac_muladd_22s_11ns_17ns_33_1_1_U105 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE mul_ln102_15 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op mul}} {BINDTYPE op ID {} IMPL dsp_slice LATENCY 0 OPTYPE add PRAGMA {} RTLNAME mac_muladd_22s_11ns_17ns_33_1_1_U105 SOURCE firmware/nnet_utils/nnet_layernorm.h:102 VARIABLE add_ln102_7 LOOP {} BUNDLEDNAME {} DSP 1 BRAM 0 URAM 0 STORAGESUBTYPE {} DISPNAME {bind_op add}} {BINDTYPE storage ID {} IMPL auto LATENCY 1 OPTYPE rom_1p PRAGMA {} RTLNAME invert_sqr_table_U SOURCE {} VARIABLE invert_sqr_table LOOP {} BUNDLEDNAME {} DSP 0 BRAM 2 URAM 0 STORAGESUBTYPE {} STORAGESIZE {8 4096 1} STORAGEUSAGE rom_1p DISPNAME {bind_storage rom_1p}}} AREA {DSP 24 BRAM 2 URAM 0}} transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s {AREA {DSP 0 BRAM 0 URAM 0}} transpose_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config4_s {AREA {DSP 0 BRAM 0 URAM 0}} layernormalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s {AREA {DSP 240 BRAM 20 URAM 0}} myproject {AREA {DSP 240 BRAM 20 URAM 0}}}}'
INFO-FLOW: DBG:PUTS:      update_csynth_reports json2rpt_hw_sw_interfaces
INFO-FLOW: Running: gen_csynth_sec_pragma
INFO-FLOW: Done: gen_csynth_sec_pragma time: 0.1 seconds per iteration
INFO-FLOW: DBG:PUTS:      update_csynth_reports wrote xml
INFO-FLOW: DBG:PUTS:      update_csynth_reports appended to csynth rpt file
INFO: [HLS 200-111] Finished Updating report files: CPU user time: 2.8 seconds. CPU system time: 0.04 seconds. Elapsed time: 2.85 seconds; current allocated memory: 495.707 MB.
INFO: [VHDL 208-304] Generating VHDL RTL for myproject.
INFO: [VLOG 209-307] Generating Verilog RTL for myproject.
Execute         syn_report -model myproject -printsummary 
INFO: [HLS 200-789] **** Estimated Fmax: 235.18 MHz
Command       autosyn done; 7.1 sec.
Command     csynth_design done; 50.3 sec.
INFO: [HLS 200-111] Finished Command csynth_design CPU user time: 41.57 seconds. CPU system time: 2.62 seconds. Elapsed time: 50.3 seconds; current allocated memory: 241.773 MB.
Execute     add_files -tb myproject_test.cpp -cflags -std=c++0x -DRTL_SIM 
INFO: [HLS 200-1510] Running: add_files -tb myproject_test.cpp -cflags -std=c++0x -DRTL_SIM 
INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project
Execute     cosim_design -trace_level all -setup 
INFO: [HLS 200-1510] Running: cosim_design -trace_level all -setup 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
INFO-FLOW: DBG:PUTS: read_platform_lib /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl
Execute       source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/common.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/APCoreGen.gen 
Execute       source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/op.gen 
Execute       source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/op_simcore.gen 
Execute       source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/generic/autopilot/interface.gen 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute       source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/common/xilinx.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/plb46.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/axi4.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/nativeAXI4.gen 
Execute           source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/saxilite.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/scripts/xilinxcoregen.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/interface/XilEDKCoreGen.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/dds_compiler.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/util.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/xfft.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/ip/xfir.gen 
Execute         source /opt/Xilinx/Vitis_HLS/2023.2/common/technology/xilinx/DSP48/dsp48.gen 
Execute       ap_part_info -name xcvu13p-flga2577-2-e -data names -quiet 
Execute       ap_part_info -name xcvu13p-flga2577-2-e -data info -quiet 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
INFO: [COSIM 212-47] Using XSIM for RTL simulation.
INFO: [COSIM 212-14] Instrumenting C test bench ...
Execute       ap_part_info -name xcvu13p-flga2577-2-e -data info 
INFO-FLOW: TB processing: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_test.cpp /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/./sim/autowrap/testbench/myproject_test.cpp_pre.cpp
Execute       clang_tidy xilinx-tb-process -desc tb-process /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/./sim/autowrap/testbench/myproject_test.cpp_pre.cpp.tb.cpp std=c++0x 
INFO-FLOW: exec /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang-tidy -header-filter=.* --checks=-*,xilinx-tb-process -fix-errors /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/./sim/autowrap/testbench/myproject_test.cpp_pre.cpp.tb.cpp -- -std=c++0x -fhls -ferror-limit=0
Command       clang_tidy done; 2.74 sec.
Execute       ap_part_info -name xcvu13p-flga2577-2-e -data info 
INFO-FLOW: TB processing: /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/firmware/myproject.cpp /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/./sim/autowrap/testbench/myproject.cpp_pre.cpp
Execute       clang_tidy xilinx-tb-process -desc tb-process /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/./sim/autowrap/testbench/myproject.cpp_pre.cpp.tb.cpp std=c++0x 
INFO-FLOW: exec /opt/Xilinx/Vitis_HLS/2023.2/lnx64/tools/clang-3.9-csynth/bin/clang-tidy -header-filter=.* --checks=-*,xilinx-tb-process -fix-errors /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/./sim/autowrap/testbench/myproject.cpp_pre.cpp.tb.cpp -- -std=c++0x -fhls -ferror-limit=0
Command       clang_tidy done; 6.36 sec.
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/./sim/autowrap/testbench/tb.status.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/global.setting.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.rtl_wrap.cfg.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       ap_part_info -name xcvu13p-flga2577-2-e -data info 
Execute       source .run_sim.tcl 
INFO: [COSIM 212-302] Starting C TB testing ... 
Command       ap_source done; 0.12 sec.
INFO: [COSIM 212-333] Generating C post check test bench ...
INFO: [COSIM 212-12] Generating RTL test bench ...
Execute       source ../tv/cdatafile/ref.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source ../tv/cdatafile/ref.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.DependenceCheck.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
Execute       source /data/hlssynt-users/rflynn/transformer-synthesis/hls4ml_projects/pytorch_layernorm_tuning/myproject_prj/solution1/.autopilot/db/myproject.tbgen.tcl 
INFO: [COSIM 212-1] *** C/RTL co-simulation file generation completed. ***
INFO: [COSIM 212-211] II is measurable only when transaction number is greater than 1 in RTL simulation. Otherwise, they will be marked as all NA. If user wants to calculate them, please make sure there are at least 2 transactions in RTL simulation.
Command     cosim_design done; 28.25 sec.
INFO: [HLS 200-111] Finished Command cosim_design CPU user time: 25.39 seconds. CPU system time: 2.26 seconds. Elapsed time: 28.25 seconds; current allocated memory: 14.836 MB.
Execute     source ./project.tcl 
Execute     source run_sim.tcl 
Execute       source check_sim.tcl 
Execute       source dataflow_monitor_API.tcl 
INFO: [COSIM 212-302] Starting C TB testing ...  
INFO: [COSIM 212-323] Starting verilog simulation...
INFO: [COSIM 212-15] Starting XSIM ...
INFO: [COSIM 212-316] Starting C post checking ...
Command     ap_source done; 17.1 sec.
Execute     cleanup_all 
Command     cleanup_all done; 0.12 sec.
